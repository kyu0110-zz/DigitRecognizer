{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in data using pandas\n",
    "df_train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split (training) data into training and testing sets\n",
    "def split_data(df, fraction=0.9): \n",
    "    # get pixels and labels\n",
    "    pixels = df.iloc[:,1:785].as_matrix()\n",
    "    labels = df.iloc[:,0].as_matrix()\n",
    "    \n",
    "    # normalize data\n",
    "    pixels = pixels / 255.0\n",
    "    #pixels = pixels / np.sum(pixels, axis=1)[:,None]\n",
    "    \n",
    "    # split into training and testing\n",
    "    n = pixels.shape[0]\n",
    "    pixels_train = pixels[0:int(fraction * n)]\n",
    "    pixels_test = pixels[int(fraction * n):n]\n",
    "    labels_train = labels[0:int(fraction * n)]\n",
    "    labels_test = labels[int(fraction * n):n]\n",
    "    \n",
    "    return pixels_train, pixels_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "K-nearest neighbors is a simple algoritm that computes the distance between an unlabeld image and the images that are labelled. The K images with the shortest distance and selected and the most frequently occuring label is assigned to the unlabelled image. K-NN does not require any prior training on the data and instead all the computation is done during classification. \n",
    "\n",
    "I compute the distance using both the Euclidean (L2) norm and the L3 norm (which got better results according the MNIST data page). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# knn function\n",
    "def KNN(pixels_labeled, pixels_unlabeled, labels, K, norm):\n",
    "    \n",
    "    n = len(pixels_unlabeled)\n",
    "    predictions = np.zeros(n)\n",
    "    \n",
    "    # loop through each item in the unlabelled dataset\n",
    "    for i in range(0, n):\n",
    "        pixel = pixels_unlabeled[i]\n",
    "        \n",
    "        # compute distance to labelled data\n",
    "        dist = np.power( np.sum(np.power((pixel - pixels_labeled), norm), axis=1), 1.0/norm )\n",
    "        \n",
    "        # select K nearest neighbors\n",
    "        indices = np.argsort(dist)\n",
    "        top_labels = labels[indices[0:K]]\n",
    "    \n",
    "        # what is majority label for these elements?\n",
    "        predictions[i] = stats.mode(top_labels).mode\n",
    "        \n",
    "        if (i % 1000 == 0): \n",
    "            print('i = ', i)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(df_train, fraction = 0.8)\n",
    "\n",
    "pred = KNN(X_train, X_test, y_train, k, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent error using L2 norm 3.04761904762\n"
     ]
    }
   ],
   "source": [
    "percent_error = np.sum(pred != y_test) / len(y_test) * 100\n",
    "print('Percent error using L2 norm', percent_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  0\n",
      "i =  1000\n",
      "i =  2000\n",
      "i =  3000\n",
      "i =  4000\n",
      "i =  5000\n",
      "i =  6000\n",
      "i =  7000\n",
      "i =  8000\n",
      "Percent error using L3 norm 80.869047619\n"
     ]
    }
   ],
   "source": [
    "# Now we try L3 norm \n",
    "pred = KNN(X_train, X_test, y_train, k, 3.0)\n",
    "percent_error = np.sum(pred != y_test) / len(y_test) * 100\n",
    "print('Percent error using L3 norm', percent_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  0\n",
      "i =  1000\n",
      "i =  2000\n",
      "i =  3000\n",
      "i =  4000\n",
      "i =  5000\n",
      "i =  6000\n",
      "i =  7000\n",
      "i =  8000\n",
      "i =  9000\n",
      "i =  10000\n",
      "i =  11000\n",
      "i =  12000\n",
      "i =  13000\n",
      "i =  14000\n",
      "i =  15000\n",
      "i =  16000\n",
      "i =  17000\n",
      "i =  18000\n",
      "i =  19000\n",
      "i =  20000\n",
      "i =  21000\n",
      "i =  22000\n",
      "i =  23000\n",
      "i =  24000\n",
      "i =  25000\n",
      "i =  26000\n",
      "i =  27000\n"
     ]
    }
   ],
   "source": [
    "# Looks like L3 norm performed terribly -- did not look at paper that was referred to, I must be missing something\n",
    "# We will use L2 norm one to generate the final classifications on the test data\n",
    "X_train, X_null, y_train, y_null = split_data(df_train, fraction = 1.0)\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "pixels_unlabeled = df_test.as_matrix()\n",
    "final_pred = KNN(X_train, pixels_unlabeled, y_train, k, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df_pred = pd.DataFrame()\n",
    "df_pred['ImageId'] = range(1,28001)\n",
    "df_pred['Label'] = final_pred.astype(int)\n",
    "df_pred.to_csv('KNN.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
