{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# packages to import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in data using pandas\n",
    "df_train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split (training) data into training and testing sets\n",
    "def split_data(df, fraction=0.9): \n",
    "    # get pixels and labels\n",
    "    pixels = df.iloc[:,1:785].as_matrix()\n",
    "    labels = df.iloc[:,0].as_matrix()\n",
    "    \n",
    "    # normalize data\n",
    "    pixels = pixels / 255.0\n",
    "    #pixels = pixels / np.sum(pixels, axis=1)[:,None]\n",
    "    \n",
    "    # add column that is just ones for offset\n",
    "    pixels = np.c_[pixels, np.ones(len(pixels))]\n",
    "    \n",
    "    # split into training and testing\n",
    "    n = pixels.shape[0]\n",
    "    pixels_train = pixels[0:int(fraction * n)]\n",
    "    pixels_test = pixels[int(fraction * n):n]\n",
    "    labels_train = labels[0:int(fraction * n)]\n",
    "    labels_test = labels[int(fraction * n):n]\n",
    "    \n",
    "    return pixels_train, pixels_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df_train, fraction=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN \n",
    "sklearn method produces similar error rate as my code (but so much faster!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent error using KNN is  2.94047619048\n"
     ]
    }
   ],
   "source": [
    "# build model and fit\n",
    "neigh = neighbors.KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "neigh.fit(X_train, y_train) \n",
    "\n",
    "# make predictions\n",
    "a = neigh.predict(X_test)\n",
    "\n",
    "# compute error\n",
    "err = (np.sum(a != y_test) / len(y_test)) * 100\n",
    "print('The percent error using KNN is ', err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "Also get similar error, but much much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build model \n",
    "lm = linear_model.LogisticRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.082380952380952374"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute error\n",
    "np.sum(pred != y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model \n",
    "classifier = svm.SVC()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.062857142857142861"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute error\n",
    "np.sum(pred != y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build model and fit\n",
    "X_train_full, X_null, y_train_full, y_null = split_data(df_train, fraction=1.0)\n",
    "neigh.fit(X_train_full, y_train_full) \n",
    "\n",
    "# make predictions\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "pixels = df_test.as_matrix()\n",
    "pixels = np.c_[pixels, np.ones(len(pixels))]\n",
    "predictions = neigh.predict(pixels)\n",
    "\n",
    "# write to csv\n",
    "df_pred = pd.DataFrame()\n",
    "df_pred['ImageId'] = range(1,28001)\n",
    "df_pred['Label'] = predictions\n",
    "df_pred.to_csv('sklearn_knn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "Based on the scripts on Kaggle, random forest seems to do well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent error using random forest is  5.72619047619\n"
     ]
    }
   ],
   "source": [
    "# build model and fit\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf.fit(X_train, y_train) \n",
    "\n",
    "# make predictions\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# compute error\n",
    "err = (np.sum(pred != y_test) / len(y_test)) * 100\n",
    "print('The percent error using random forest is ', err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf.fit(X_train_full, y_train_full) \n",
    "\n",
    "# make predictions\n",
    "predictions = rf.predict(pixels)\n",
    "\n",
    "# write to csv\n",
    "df_pred = pd.DataFrame()\n",
    "df_pred['ImageId'] = range(1,28001)\n",
    "df_pred['Label'] = predictions\n",
    "df_pred.to_csv('sklearn_randomforest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
